{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho para o arquivo CSV (substitua pelo caminho correto)\n",
    "caminho = \"C:\\\\Users\\\\joaom\\\\Downloads\\\\ObesityDataSet_raw_and_data_sinthetic.csv\"  # Exemplo de caminho no Windows\n",
    "\n",
    "# Carregar o CSV para um DataFrame\n",
    "df = pd.read_csv(caminho)\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixar o matplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré Processamento do Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Criar o codificador\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Aplicar o Label Encoding na coluna 'Categoria'\n",
    "df['NObeyesdad'] = label_encoder.fit_transform(df['NObeyesdad'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré Processamento One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colunas_para_codificar = ['Gender', 'family_history_with_overweight',\n",
    "       'FAVC', 'CAEC', 'SMOKE', 'SCC',\n",
    "       'CALC', 'MTRANS']\n",
    "\n",
    "df = pd.get_dummies(df, columns=colunas_para_codificar)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalização dos Valores numéricos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Criar o MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Colunas que você quer normalizar\n",
    "columns_normalize = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "\n",
    "# Normalizar apenas as colunas selecionadas\n",
    "df[columns_normalize] = scaler.fit_transform(df[columns_normalize])\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise de Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcular a correlação entre as variáveis\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Exibir a correlação entre as variáveis independentes e a variável alvo (y)\n",
    "print(correlation_matrix['NObeyesdad'].sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir dados em teste e treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df.drop('NObeyesdad', axis=1)  # Colunas de entrada\n",
    "y = df['NObeyesdad']  # Target (saída)\n",
    "\n",
    "# Dividir os dados em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinar Árvore de Decisão (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "# Criar o modelo da árvore de decisão\n",
    "dt_classifier = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Exibir a acurácia do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Exibir um relatório de classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinar Árvore de Decisão ( Entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o modelo da árvore de decisão\n",
    "dt_classifier = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Exibir a acurácia do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Exibir um relatório de classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Treinar o modelo\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Avaliar a performance do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Exibir um relatório de classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "# Treinar o modelo\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Avaliar a performance do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Exibir um relatório de classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP (Relu e 2 camadas ocultas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "mlp_1 = MLPClassifier(hidden_layer_sizes=(50, 30), activation='relu', random_state=42)\n",
    "mlp_1.fit(X_train, y_train)\n",
    "y_pred_1 = mlp_1.predict(X_test)\n",
    "\n",
    "# Avaliar a Arquitetura 1\n",
    "print(\"Arquitetura 1 (activation='relu'):\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred_1):.2f}\")\n",
    "print(classification_report(y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP (Relu 3 camadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mlp_2= MLPClassifier(hidden_layer_sizes=(100,50,25), activation='relu', random_state=42)\n",
    "mlp_2.fit(X_train, y_train)\n",
    "y_pred_2 = mlp_2.predict(X_test)\n",
    "\n",
    "print(\"Arquitetura 2 (activation='relu'):\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred_2):.2f}\")\n",
    "print(classification_report(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP (tahn e 2 camadas ocultas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_3 = MLPClassifier(hidden_layer_sizes=(50,30), activation='tanh', random_state=42)\n",
    "mlp_3.fit(X_train, y_train)\n",
    "y_pred_3 = mlp_3.predict(X_test)\n",
    "\n",
    "# Avaliar a Arquitetura 2\n",
    "print(\"\\nArquitetura 1 (activation='tanh'):\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred_3):.2f}\")\n",
    "print(classification_report(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPL (tah e 3 camadas ocultas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_4 = MLPClassifier(hidden_layer_sizes=(100, 50,25), activation='tanh', random_state=42)\n",
    "mlp_4.fit(X_train, y_train)\n",
    "y_pred_4 = mlp_4.predict(X_test)\n",
    "\n",
    "print(\"\\nArquitetura 2 (activation='tanh'):\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred_4):.2f}\")\n",
    "print(classification_report(y_test, y_pred_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means (k igual a 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=42)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "def map_clusters_to_classes(kmeans, y_train):\n",
    "    # Criar um dicionário de mapeamento cluster -> classe\n",
    "    mapping = {}\n",
    "    \n",
    "    for cluster_id in range(kmeans.n_clusters):\n",
    "        # Encontrar o rótulo mais comum (modo) para cada cluster\n",
    "        cluster_data = y_train[kmeans.labels_ == cluster_id]\n",
    "        most_common_class = np.bincount(cluster_data).argmax()\n",
    "        mapping[cluster_id] = most_common_class\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "# 6.2) Aplicando o mapeamento para os clusters no conjunto de teste\n",
    "mapping = map_clusters_to_classes(kmeans, y_train)\n",
    "y_pred = np.array([mapping[cluster_id] for cluster_id in kmeans.predict(X_test)])\n",
    "\n",
    "# 7) Mostrar a taxa de acerto do K-Means\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Taxa de acerto do K-Means: {accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protocolo Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 3. Definir o k-fold cross-validation (k=10)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# 4. Definir os algoritmos a serem usados\n",
    "models = {\n",
    "    \"KMeans (k=10)\": KMeans(n_clusters=7, random_state=42),\n",
    "    \"Árvore de Decisão (gini)\": DecisionTreeClassifier(criterion='gini',random_state=42),\n",
    "    \"Árvore de Decisão (entropy)\": DecisionTreeClassifier(criterion='entropy',random_state=42),\n",
    "    \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5, metric='euclidean'),\n",
    "    \"KNN (k=10)\": KNeighborsClassifier(n_neighbors=10, metric='euclidean'),\n",
    "    \"MLP ReLU (Arquitetura 1)\": MLPClassifier(hidden_layer_sizes=(100,), activation='relu', max_iter=1000, random_state=42),\n",
    "    \"MLP ReLU (Arquitetura 2)\": MLPClassifier(hidden_layer_sizes=(200, 100), activation='relu', max_iter=1000, random_state=42),\n",
    "    \"MLP tanh (Arquitetura 1)\": MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', max_iter=1000, random_state=42),\n",
    "    \"MLP tanh (Arquitetura 2)\": MLPClassifier(hidden_layer_sizes=(200, 100), activation='tanh', max_iter=1000, random_state=42),\n",
    "}\n",
    "\n",
    "# 4. Dividir os dados em treino (90%) e teste (10%) usando train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "# 5. Executar o treinamento e teste para cada algoritmo\n",
    "results = {}\n",
    "mlp_errors = {}  # Armazenar os erros para as MLPs\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    fold_accuracies = []\n",
    "\n",
    "    # Para MLPs, queremos coletar a curva de perda\n",
    "    if 'MLP' in model_name:\n",
    "        model.set_params(verbose=True, warm_start=False)  # Enable verbose to track loss curve\n",
    "    # Treinar o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Fazer previsões no conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcular a acurácia\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    fold_accuracies.append(accuracy)\n",
    "\n",
    "    \n",
    "    # Armazenar o resultado para esse modelo\n",
    "    results[model_name] = accuracy\n",
    "\n",
    "    # Para MLP, salvar a curva de erro (loss)\n",
    "    if 'MLP' in model_name:\n",
    "        if model_name not in mlp_errors:\n",
    "            mlp_errors[model_name] = []\n",
    "        mlp_errors[model_name].append(model.loss_curve_)\n",
    "\n",
    "    results[model_name] = np.mean(fold_accuracies)\n",
    "\n",
    "\n",
    "# 6. Exibir os resultados finais\n",
    "for model_name, accuracy in results.items():\n",
    "    print(f\"{model_name}: Acurácia em 90% treino / 10% teste: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 7. Exibir os resultados finais\n",
    "print(\"\\nResultados Finais (Acurácia Média em 10 folds):\")\n",
    "for model_name, accuracy in results.items():\n",
    "    print(f\"{model_name}: Acurácia: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 8. Gráfico de Taxa de Erro para MLPs\n",
    "for model_name, loss_curves in mlp_errors.items():\n",
    "    if len(loss_curves) > 0:\n",
    "        avg_loss_curve = np.mean(loss_curves, axis=0)  # Média da perda ao longo das épocas\n",
    "        epochs = np.arange(len(avg_loss_curve))  # Número de épocas\n",
    "        plt.plot(epochs, avg_loss_curve, label=model_name)\n",
    "\n",
    "plt.title('Taxa de Erro de Treinamento para MLPs')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Função de Perda (Erro)')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 9. Tabela com as Taxas de Erro/Acerto para cada algoritmo\n",
    "results_table = pd.DataFrame.from_dict(results, orient='index', columns=['Acurácia Média'])\n",
    "results_table['Taxa de Erro Média'] = 1 - results_table['Acurácia Média']\n",
    "results_table = results_table.sort_values(by='Acurácia Média', ascending=False)\n",
    "\n",
    "# Exibir tabela\n",
    "print(\"\\nTabela de Resultados:\")\n",
    "print(results_table * 100)  # Multiplicar por 100 para mostrar como percentual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
